
---
title: Geraud Nangue Tasse
surname: Nangue Tasse
weight: 5
role: Lecturer
bio: I am interested in reinforcement learning (RL) since it is the subfield of machine learning with the most potential for achieving AGI. 
interests:
  - Reinforcement Learning
  - Deep Learning
  - Deep Reinforcement Learning
social:
  - icon: envelope
    icon_pack: fas
    link: mailto:geraudnt@gmail.com

  - icon: google-scholar
    icon_pack: ai
    link: https://scholar.google.com/citations?user=CAfsMIsAAAAJ&hl=en

  - icon: globe
    icon_pack: fas
    link: https://geraudnt.github.io/

  - icon: github
    icon_pack: fab
    link: https://github.com/geraudnt

  - icon: linkedin
    icon_pack: fab
    link: https://www.linkedin.com/in/geraud-nangue-tasse-264281a5/

organizations:
  - name: University of the Witwatersrand
    url: https://www.wits.ac.za/csam/

superuser: false
user_groups:
  - Faculty
  - Alumni
highlight_name: true
grad_info: MSc, 2020; PhD 2024

---

I have always been fascinated by the immense potential for good of creating intelligent systems---the pinnacle of which is artificial general intelligence (AGI). Towards the end of acheiving AGI, I am currently interested in techniques that allow an agent to leverage past knowledge to solve new tasks quickly. In particular, I focus on composition techniques. These allow an agent to leverage existing skills to build complex, novel behaviors. During my M.Sc research, I introduced a formal framework for specifying tasks using logic operators (AND, OR, NOT), and how to similarly apply them on learned skills to generate provably optimal solutions to new tasks. Not only does this allow for safer and interpretable reward specification---since any new task reward function can be composed of well-understood components---it also leads to a combinatorial explosion in an agentâ€™s ability. These are particularly important for agents in a multitask or lifelong setting.

Here are a couple longterm milestones I think are needed on the road to AGI, and which I am working towards:

* A provably general knowledge representation for transfer learning in RL, but not too general (it needs to be sufficiently constrained to be practical).

* Principled methods for efficiently learning base skills with said knowledge represention.

* Principled methods for agents to do any computation over skills with no/minimal further learning. That is, creating agents that are Turing complete in skill space.

