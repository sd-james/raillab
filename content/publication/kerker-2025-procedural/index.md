---
title:  "Procedural Generation of Semantically Correct Levels in Video Games using Reward Shaping"
authors:
  - Luke Kerker
  - Branden Ingram
  - Pravesh Ranchod

author_notes: []

publication: "*Reinforcement Learning and Video Games Workshop at RLC*"

date: 2025-08-05T00:00:00Z
publishDate: 2022-10-05T00:00:00Z

# conf = 1, journal = 2, preprint = 3, report = 4, book = 5, book chapter = 6, thesis = 7, patent = 9
# workshop = 9, symposium = 10, extended abstract =11
publication_types:
- "9"

abstract: "The generation of video game levels traditionally relies on manual efforts from skilled professionals, resulting in significant expenses and time commitments. Procedural generation offers a solution by automating this process, reducing costs but potentially sacrificing designer control. The drawback of diminished control is that it has limited the widespread adoption of procedural generation due to concerns about the quality of the generated levels. Various approaches, including reinforcement learning and evolutionary algorithms, have been explored to address this limitation by improving how procedurally generated levels align with designer constraints. However, a key challenge remains in designing reward schemes or evaluation functions that accurately capture these constraints. To tackle this challenge, this paper proposes a system utilizing semantically appropriate reward shaping in a reinforcement learning setting for procedural content generation. By integrating an additional shaping function into the reward mechanism, this system generates diverse video game levels in the Zelda Gym environment that meet designersâ€™ specific requirements and constraints."
  
featured: true
tags:
  - Procedural Content Generation
  - Reinforcement Learning
  - Games

projects:
  - ai-in-games

image:
focal_point: ''
preview_only: false

slides: null

#url_dataset: "#"
#url_project: ""
#publication_short: ""
#url_source: "#"
#url_video: "#"
#url_slides: ""
#url_poster: "#"
#url_code: "#"
# doi: ""
---
