---
title:  "Will it Blend? Composing Value Functions in Reinforcement Learning"
authors:
  - Benjamin Van Niekerk
  - Steven James
  - Adam Earle
  - Benjamin Rosman
  
author_notes: []

publication: "*The 2nd Lifelong Learning: A Reinforcement Learning Approach (LLARLA) Workshop @ FAIM*"

date: 2018-07-14T00:00:00Z
publishDate: 2022-10-05T00:00:00Z

# conf = 1, journal = 2, preprint = 3, report = 4, book = 5, book chapter = 6, thesis = 7, patent = 9
# workshop = 9, symposium = 10, extended abstract =11
publication_types:
  - "9"

abstract: "An important property for lifelong-learning
  agents is the ability to combine existing skills
  to solve unseen tasks. In general, however, it is
  unclear how to compose skills in a principled way.
  We provide a “recipe” for optimal value function
  composition in entropy-regularised reinforcement
  learning (RL) and then extend this to the standard
  RL setting. Composition is demonstrated in a
  video game environment, where an agent with an
  existing library of policies is able to solve new
  tasks without the need for further learning."

featured: true
tags:
  - Reinforcement Learning
  - Composition
  - Entropy-regularised Reinforcement Learning

image:
  focal_point: ''
  preview_only: false

projects:
  - composition


slides: null

#url_dataset: "#"
#url_project: ""
#publication_short: ""
#url_source: "#"
#url_slides: ""
#url_poster: "#"
#url_code: "#"
# doi: ""



---
