---
title:  "Knowledge Transfer using Model-Based Deep Reinforcement Learning"
authors:
  - Tlou Boloka
  - Ndivhuwo Makondo
  - Benjamin Rosman

author_notes: []

publication: "In *Proceedings of the IEEE SAUPEC/ROBMECH/PRASA International Conference*"

date: 2021-01-28T00:00:00Z
publishDate: 2022-10-05T00:00:00Z

# conf = 1, journal = 2, preprint = 3, report = 4, book = 5, book chapter = 6, thesis = 7, patent = 9
# workshop = 9, symposium = 10, extended abstract =11
publication_types:
  - "1"

abstract: Deep reinforcement learning has recently been
  adopted for robot behavior learning, where robot skills are
  acquired and adapted from data generated by the robot while
  interacting with its environment through a trial-and-error process.
  Despite this success, most model-free deep reinforcement
  learning algorithms learn a task-specific policy from a clean
  slate and thus suffer from high sample complexity (i.e., they
  require a significant amount of interaction with the environment
  to learn reasonable policies and even more to reach convergence).
  They also suffer from poor initial performance due to executing
  a randomly initialized policy in the early stages of learning to
  obtain experience used to train a policy or value function. Model-based
  deep reinforcement learning mitigates these shortcomings.
  However, it suffers from poor asymptotic performance in contrast
  to a model-free approach. In this work, we investigate knowledge
  transfer from a model-based teacher to a task-specific model-free
  learner to alleviate executing a randomly initialized policy
  in the early stages of learning. Our experiments show that this
  approach results in better asymptotic performance, enhanced
  initial performance, improved safety, better action effectiveness,
  and reduced sample complexity.

featured: true
tags:
  - Reinforcement Learning
  - Transfer Learning
  

image:
  focal_point: ''
  preview_only: false

slides: null
---
