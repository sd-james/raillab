---
title:  "GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps"
authors:
  - Muhammad Nasir
  - Steven James
  - Julian Togelius

author_notes: []

publication: "*Advances in Neural Information Processing Systems*"

date: 2024-12-10T00:00:00Z
publishDate: 2022-10-05T00:00:00Z

# conf = 1, journal = 2, preprint = 3, report = 4, book = 5, book chapter = 6, thesis = 7, patent = 9
# workshop = 9, symposium = 10, extended abstract =11
publication_types:
  - "1"

abstract: "Large language models (LLMs) have recently demonstrated great success in generating and understanding natural 
  language. While they have also shown potential beyond the domain of natural language, it remains an open question as 
  to what extent and in which way these LLMs can plan. We investigate their planning capabilities by proposing 
  GameTraversalBenchmark (GTB), a benchmark consisting of diverse 2D grid-based game maps. An LLM succeeds if 
  it can traverse through given objectives, with a minimum number of steps and a minimum number of generation errors.
  We evaluate a number of LLMs on GTB and found that GPT-4-Turbo achieved the highest score of 44.97% on GTB_Score (GTBS), 
  a composite score that combines the three above criteria. Furthermore, we preliminarily test large reasoning 
  models, namely o1, which scores 67.84% on GTBS, indicating that the benchmark remains challenging for current models. 
  Code, data, and documentation are available at https://github.com/umair-nasir14/Game-Traversal-Benchmark."


featured: true
tags:
  - Benchmark
  - Large Language Models
  - Dataset
  
  
image:
  focal_point: ''
  preview_only: false

slides: null

url_code: "https://github.com/umair-nasir14/Game-Traversal-Benchmark"
---
