---
title:  "Quantisation and Pruning for Neural Network Compression and Regularisation"
authors:
  - Kimessha Paupamah
  - Steven James
  - Richard Klein

author_notes: []

publication: "*International SAUPEC/RobMech/PRASA Conference*"

date: 2020-01-29T00:00:00Z
publishDate: 2022-10-05T00:00:00Z

# conf = 1, journal = 2, preprint = 3, report = 4, book = 5, book chapter = 6, thesis = 7, patent = 9
# workshop = 9, symposium = 10, extended abstract =11
publication_types:
- "1"

abstract: "Deep neural networks are typically too computationally
  expensive to run in real-time on consumer-grade hardware
  and low-powered devices. In this paper, we investigate reducing
  the computational and memory requirements of neural networks
  through network pruning and quantisation. We examine their efficacy
  on large networks like AlexNet compared to recent compact
  architectures: ShuffleNet and MobileNet. Our results show that
  pruning and quantisation compresses these networks to less than
  half their original size and improves their efficiency, particularly
  on MobileNet with a 7x speedup. We also demonstrate that
  pruning, in addition to reducing the number of parameters in a
  network, can aid in the correction of overfitting."

featured: true
tags:
  - Deep Learning
  - Neural Networks
  - Pruning
  - Compression

image:
focal_point: ''
preview_only: false

slides: null

#url_dataset: "#"
#url_project: ""
#publication_short: ""
#url_source: "#"
#url_video: "#"
#url_slides: ""
#url_poster: "#"
#url_code: "#"
# doi: ""
---
